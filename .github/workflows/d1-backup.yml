name: D1 Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for manual backup'
        required: false
        default: 'Manual backup'

jobs:
  backup:
    name: Backup D1 Database
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Wrangler
        run: npm install -g wrangler

      - name: Create backup
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          # Generate backup filename with timestamp
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_FILE="heirloom-db-backup-${TIMESTAMP}.sql"
          
          echo "Creating D1 backup: $BACKUP_FILE"
          
          # Export D1 database to SQL
          # Note: This requires the CLOUDFLARE_API_TOKEN secret to be set
          # with D1 read permissions
          wrangler d1 export heirloom-db --output="$BACKUP_FILE" || {
            echo "Warning: D1 export failed. This may be due to missing API token."
            echo "Please set CLOUDFLARE_API_TOKEN secret with D1 read permissions."
            exit 0
          }
          
          # Compress the backup
          gzip "$BACKUP_FILE"
          
          echo "Backup created: ${BACKUP_FILE}.gz"
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV

      - name: Upload to R2 (if configured)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          if [ -f "$BACKUP_FILE" ]; then
            echo "Uploading backup to R2..."
            # Upload to R2 bucket using wrangler
            wrangler r2 object put "heirloom-uploads/backups/$BACKUP_FILE" --file="$BACKUP_FILE" || {
              echo "Warning: R2 upload failed. Backup saved as artifact instead."
            }
          fi
        continue-on-error: true

      - name: Upload backup as artifact
        uses: actions/upload-artifact@v4
        with:
          name: d1-backup-${{ github.run_id }}
          path: "*.sql.gz"
          retention-days: 30
          if-no-files-found: warn

      - name: Cleanup old backups in R2
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "Cleaning up backups older than 30 days..."
          # List and delete old backups (keeping last 30 days)
          # This is a placeholder - actual implementation depends on R2 lifecycle policies
          echo "Note: Configure R2 lifecycle rules for automatic cleanup"
        continue-on-error: true

      - name: Send notification on failure
        if: failure()
        run: |
          echo "Backup failed! Please check the logs."
          # Add notification logic here (e.g., Slack, email)
